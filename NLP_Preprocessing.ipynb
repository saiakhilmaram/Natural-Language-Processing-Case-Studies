{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpbMEHUi7sY1"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZYpllFE7xCC"
   },
   "outputs": [],
   "source": [
    "#Load Predefined model which understand English Language\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGZIqsTd73Mb",
    "outputId": "16bb8fe8-2465-4088-8190-4f2cb2270f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more.\n"
     ]
    }
   ],
   "source": [
    "text_data = \"Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more.\"\n",
    "print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQXEmZmF7-_B",
    "outputId": "976cbff2-f283-482f-c3dd-5c753e796128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text_data)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FncsuzK18Bnn",
    "outputId": "de585165-4a1e-471a-957a-570cbc9da9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "Language\n",
      "Processing\n",
      "with\n",
      "Python\n",
      "provides\n",
      "a\n",
      "practical\n",
      "introduction\n",
      "to\n",
      "programming\n",
      "for\n",
      "language\n",
      "processing\n",
      ".\n",
      "Written\n",
      "by\n",
      "the\n",
      "creators\n",
      "of\n",
      "NLTK\n",
      ",\n",
      "it\n",
      "guides\n",
      "the\n",
      "reader\n",
      "through\n",
      "the\n",
      "fundamentals\n",
      "of\n",
      "writing\n",
      "Python\n",
      "programs\n",
      ",\n",
      "working\n",
      "with\n",
      "corpora\n",
      ",\n",
      "categorizing\n",
      "text\n",
      ",\n",
      "analyzing\n",
      "linguistic\n",
      "structure\n",
      ",\n",
      "and\n",
      "more\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ai4D-DTV8Pz_",
    "outputId": "cab4c3b4-beaf-4c20-ecbc-b3e5337699c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8P83BvK2J7gs",
    "outputId": "230b211a-faf6-4d87-f74f-c26857751a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'with', 'Python', 'provides', 'a', 'practical', 'introduction', 'to', 'programming', 'for', 'language', 'processing', '.', 'Written', 'by', 'the', 'creators', 'of', 'NLTK', ',', 'it', 'guides', 'the', 'reader', 'through', 'the', 'fundamentals', 'of', 'writing', 'Python', 'programs', ',', 'working', 'with', 'corpora', ',', 'categorizing', 'text', ',', 'analyzing', 'linguistic', 'structure', ',', 'and', 'more', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mz_sFT-UKFTO",
    "outputId": "44588605-6aba-4b58-ab6c-9b9c4c28edd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rather', '‘d', 'therefore', 'further', 'ours', 'must', 'before', 'elsewhere', 'where', 'two', 'keep', 'thence', 'be', 'these', 'front', 'whom', 'move', 'during', 'after', 'that', 'are', 'whither', '‘re', 'get', 'per', 'sometimes', '’m', 'he', 'say', 'sometime', 'all', 'back', 'thru', 'hundred', 'itself', 'up', 'seem', 'this', 'from', 'was', 'every', 'regarding', 'whenever', 'same', 'do', 'since', 'of', 'less', 'have', 'well', 'whereas', 'along', 'otherwise', 'you', 'ten', 'becoming', 'someone', 'had', 'third', 'them', 'can', 'the', 'also', '‘ll', 'anything', 'against', 'and', 're', 'via', 'as', 'herein', 'there', 'almost', 'meanwhile', 'into', 'everywhere', 'amongst', \"'re\", 'neither', 'were', 'nor', 'not', 'until', 'whose', 'below', 'hers', 'sixty', '‘s', 'n’t', 'however', \"'d\", 'onto', 'though', 'i', 'towards', '‘ve', 'first', 'cannot', 'their', 'somehow', \"n't\", '’ve', 'nine', 'to', \"'ve\", 'more', 'except', 'few', 'twelve', 'amount', 'no', 'top', 'whence', 'seeming', \"'m\", 'part', 'once', 'fifteen', 'forty', 'namely', 'us', 'been', 'take', 'whether', 'our', 'beforehand', 'seemed', 'full', 'she', 'his', 'other', 'already', 'beyond', 'see', '’d', 'anyhow', 'moreover', 'whatever', 'yet', 'thereafter', 'in', \"'s\", 'several', 'else', 'by', 'what', 'throughout', 'your', '’re', 'himself', 'toward', 'again', 'besides', 'down', '’s', 'who', 'being', 'because', 'indeed', \"'ll\", 'am', 'me', 'so', 'such', 'most', 'those', 'afterwards', 'hereupon', 'become', 'hereafter', 'own', 'serious', 'it', 'both', 'just', 'n‘t', 'each', 'very', 'much', 'on', 'nothing', 'yourselves', 'everything', 'hereby', 'nobody', 'around', 'none', 'did', 'eight', 'thereby', 'five', 'enough', 'without', 'wherein', 'would', 'wherever', 'nevertheless', 'bottom', 'mine', 'then', 'either', 'whereby', 'yourself', 'for', 'quite', 'empty', 'ever', 'therein', 'off', '’ll', 'with', 'put', 'still', 'but', '‘m', 'themselves', 'a', 'always', 'perhaps', 'some', 'how', 'now', 'side', 'various', 'thus', 'twenty', 'many', 'when', 'noone', 'among', 'across', 'became', 'between', 'which', 'hence', 'anywhere', 'others', 'if', 'its', 'should', 'go', 'while', 'using', 'through', 'we', 'eleven', 'something', 'whereupon', 'three', 'give', 'latterly', 'another', 'four', 'myself', 'ourselves', 'ca', 'fifty', 'is', 'an', 'done', 'everyone', 'although', 'doing', 'thereupon', 'has', 'too', 'does', 'last', 'whoever', 'out', 'herself', 'here', 'her', 'becomes', 'somewhere', 'within', 'whereafter', 'might', 'six', 'above', 'next', 'call', 'formerly', 'under', 'latter', 'could', 'due', 'made', 'any', 'used', 'nowhere', 'least', 'unless', 'may', 'beside', 'or', 'anyone', 'even', 'whole', 'together', 'than', 'alone', 'at', 'name', 'mostly', 'seems', 'anyway', 'they', 'never', 'former', 'why', 'show', 'my', 'over', 'him', 'really', 'will', 'often', 'upon', 'one', 'only', 'behind', 'please', 'make', 'about', 'yours'}\n"
     ]
    }
   ],
   "source": [
    "#Stop words - words do not add much value to the text\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kay_kS2jLKZe",
    "outputId": "a307570e-e80c-4cb2-e418-9f87208669d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PU0wL_QLXue",
    "outputId": "6e6febd9-1688-4021-9d20-5593d661a831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Identify stop words in text_data \n",
    "for token in doc:\n",
    "  print(token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWVC8MQuP0Xp",
    "outputId": "a6fe5cc4-cfd6-4249-c846-f8f71ea746ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with\n",
      "a\n",
      "to\n",
      "for\n",
      "by\n",
      "the\n",
      "of\n",
      "it\n",
      "the\n",
      "through\n",
      "the\n",
      "of\n",
      "with\n",
      "and\n",
      "more\n"
     ]
    }
   ],
   "source": [
    "# Print Stop Words\n",
    "for token in doc:\n",
    "  if token.is_stop:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0vtoQIzL9eG",
    "outputId": "f585ce59-9862-4640-fcc5-754a70bc3377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Natural, Language, Processing, Python, provides, practical, introduction, programming, language, processing, ., Written, creators, NLTK, ,, guides, reader, fundamentals, writing, Python, programs, ,, working, corpora, ,, categorizing, text, ,, analyzing, linguistic, structure, ,, .]\n"
     ]
    }
   ],
   "source": [
    "#Remove all stop words from doc and store the remaning words in a list\n",
    "text_sw = []\n",
    "\n",
    "for token in doc:\n",
    "  if token.is_stop:\n",
    "    continue\n",
    "  else:\n",
    "    text_sw.append(token)\n",
    "\n",
    "print(text_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c9MIdWErM1XM",
    "outputId": "1f5da4f1-3dcc-4a96-d1d5-1f7d950df193"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>IS_PUNCTUAUTION</th>\n",
       "      <th>POS</th>\n",
       "      <th>LEMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Language</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Processing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>provides</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>provide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>practical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>practical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>introduction</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>programming</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>language</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>processing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Written</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>by</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>creators</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>creator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NLTK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NLTK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>it</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>guides</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>reader</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>through</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fundamentals</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>fundamental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>writing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Python</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>programs</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>working</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>with</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>corpora</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>corpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>categorizing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>categorize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>analyzing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>analyze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>linguistic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>linguistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>structure</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>and</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>more</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tokens Stop Words IS_PUNCTUAUTION    POS         LEMMA\n",
       "0        Natural      False           False  PROPN       Natural\n",
       "1       Language      False           False  PROPN      Language\n",
       "2     Processing      False           False  PROPN    Processing\n",
       "3           with       True           False    ADP          with\n",
       "4         Python      False           False  PROPN        Python\n",
       "5       provides      False           False   VERB       provide\n",
       "6              a       True           False    DET             a\n",
       "7      practical      False           False    ADJ     practical\n",
       "8   introduction      False           False   NOUN  introduction\n",
       "9             to       True           False    ADP            to\n",
       "10   programming      False           False   NOUN   programming\n",
       "11           for       True           False    ADP           for\n",
       "12      language      False           False   NOUN      language\n",
       "13    processing      False           False   NOUN    processing\n",
       "14             .      False            True  PUNCT             .\n",
       "15       Written      False           False   VERB         write\n",
       "16            by       True           False    ADP            by\n",
       "17           the       True           False    DET           the\n",
       "18      creators      False           False   NOUN       creator\n",
       "19            of       True           False    ADP            of\n",
       "20          NLTK      False           False  PROPN          NLTK\n",
       "21             ,      False            True  PUNCT             ,\n",
       "22            it       True           False   PRON        -PRON-\n",
       "23        guides      False           False   VERB         guide\n",
       "24           the       True           False    DET           the\n",
       "25        reader      False           False   NOUN        reader\n",
       "26       through       True           False    ADP       through\n",
       "27           the       True           False    DET           the\n",
       "28  fundamentals      False           False   NOUN   fundamental\n",
       "29            of       True           False    ADP            of\n",
       "30       writing      False           False   VERB         write\n",
       "31        Python      False           False  PROPN        Python\n",
       "32      programs      False           False   NOUN       program\n",
       "33             ,      False            True  PUNCT             ,\n",
       "34       working      False           False   VERB          work\n",
       "35          with       True           False    ADP          with\n",
       "36       corpora      False           False  PROPN       corpora\n",
       "37             ,      False            True  PUNCT             ,\n",
       "38  categorizing      False           False   VERB    categorize\n",
       "39          text      False           False   NOUN          text\n",
       "40             ,      False            True  PUNCT             ,\n",
       "41     analyzing      False           False   VERB       analyze\n",
       "42    linguistic      False           False    ADJ    linguistic\n",
       "43     structure      False           False   NOUN     structure\n",
       "44             ,      False            True  PUNCT             ,\n",
       "45           and       True           False  CCONJ           and\n",
       "46          more       True           False    ADJ          more\n",
       "47             .      False            True  PUNCT             ."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tokenized_text = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(doc):\n",
    "  tokenized_text.loc[i,'Tokens'] = token.text\n",
    "  tokenized_text.loc[i,'Stop Words'] = token.is_stop\n",
    "  tokenized_text.loc[i,'IS_PUNCTUAUTION'] = token.is_punct\n",
    "  tokenized_text.loc[i,'POS'] = token.pos_\n",
    "  tokenized_text.loc[i,'LEMMA'] = token.lemma_\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mgth2eNRH6R"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "3OMqk4Thd4_9",
    "outputId": "5339fa89-cc23-436a-bbd0-4a9fde776d9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Natural Language Processing with Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " provides a practical introduction to programming for language processing. Written by the creators of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLTK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", it guides the reader through the fundamentals of writing \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " programs, working with corpora, categorizing text, analyzing linguistic structure, and more.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = 'ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg4uQOwaeD-u",
    "outputId": "30440e7f-cf6b-43d6-9b9d-4d81452217fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing with Python ORG\n",
      "NLTK ORG\n",
      "Python ORG\n"
     ]
    }
   ],
   "source": [
    "for token in doc.ents:\n",
    "  print(token.text, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMWOzVKsepWA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Class2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
